### A Taxonomy of Security Risks in Large Language Models
 - Summary:
 This paper presents a comprehensive taxonomy of security risks associated with large language models (LLMs), focusing on prompt-based attacks that can target users, the models themselves, and third parties. It categorizes these attacks based on their target and type, providing specific examples to illustrate their potential real-world impact. The authors aim to enhance the understanding of LLM security risks and inform the development of safer and more trustworthy applications.
